{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555f6dc4-533e-4571-a4ed-aa2280c62631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fefe7-5eac-4efc-ab58-a640adff8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the YOLOv4 model configuration and weights\n",
    "yolo_model = cv2.dnn.readNetFromDarknet(r\"C:\\Users\\kopan\\OneDrive\\Desktop\\AI\\AI Codes\\yolov4.cfg\", r\"C:\\Users\\kopan\\OneDrive\\Desktop\\AI\\AI Codes\\yolov4.weights\")\n",
    "\n",
    "# Use GPU if available\n",
    "yolo_model.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "yolo_model.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Load the COCO class labels\n",
    "class_labels = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "                \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "                \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "                \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "                \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
    "                \"sofa\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\",\n",
    "                \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\",\n",
    "                \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Declare colors for different classes\n",
    "class_colors = [\"0,255,0\", \"0,0,255\", \"255,0,0\", \"255,255,0\", \"0,255,255\"]\n",
    "class_colors = [np.array(color.split(\",\")).astype(\"int\") for color in class_colors]\n",
    "class_colors = np.array(class_colors)\n",
    "class_colors = np.tile(class_colors, (16, 1))\n",
    "\n",
    "# Set up video capture\n",
    "video_path = r\"C:\\Users\\kopan\\OneDrive\\Desktop\\AI\\7.Object\\Images\\video (1).mp4\"  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# YOLOv4 layer names\n",
    "layer_names = yolo_model.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in yolo_model.getUnconnectedOutLayers()]\n",
    "\n",
    "# Process each frame of the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Prepare the frame as blob input for YOLO\n",
    "    img_blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    yolo_model.setInput(img_blob)\n",
    "    obj_detection_layers = yolo_model.forward(output_layers)\n",
    "\n",
    "    # Lists for NMS processing\n",
    "    class_ids_list = []\n",
    "    boxes_list = []\n",
    "    confidences_list = []\n",
    "\n",
    "    # Process detection outputs\n",
    "    for detection_layer in obj_detection_layers:\n",
    "        for object_detection in detection_layer:\n",
    "            scores = object_detection[5:]\n",
    "            predicted_class_id = np.argmax(scores)\n",
    "            confidence = scores[predicted_class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                box = object_detection[0:4] * np.array([frame_width, frame_height, frame_width, frame_height])\n",
    "                (center_x, center_y, width, height) = box.astype(\"int\")\n",
    "\n",
    "                start_x = int(center_x - (width / 2))\n",
    "                start_y = int(center_y - (height / 2))\n",
    "\n",
    "                # Add the box coordinates, class ID, and confidence for NMS\n",
    "                boxes_list.append([start_x, start_y, int(width), int(height)])\n",
    "                confidences_list.append(float(confidence))\n",
    "                class_ids_list.append(predicted_class_id)\n",
    "\n",
    "    # Apply Non-Maxima Suppression (NMS)\n",
    "    max_value_ids = cv2.dnn.NMSBoxes(boxes_list, confidences_list, 0.5, 0.4)\n",
    "\n",
    "    # Draw the bounding boxes and labels\n",
    "    if len(max_value_ids) > 0:\n",
    "        for i in max_value_ids.flatten():\n",
    "            (x, y) = (boxes_list[i][0], boxes_list[i][1])\n",
    "            (w, h) = (boxes_list[i][2], boxes_list[i][3])\n",
    "            color = [int(c) for c in class_colors[class_ids_list[i]]]\n",
    "            label = f\"{class_labels[class_ids_list[i]]}: {confidences_list[i]:.2f}\"\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow('YOLOv4 Video Detection', frame)\n",
    "\n",
    "    # Press 'q' to break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435d90c-03c9-4f20-b878-ce949ed28fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
